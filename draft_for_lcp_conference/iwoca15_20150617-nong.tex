\documentclass{llncs}
\usepackage[english]{babel}
\usepackage{cite}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multirow}
% THEOREMS -------------------------------------------------------
\newtheorem{thm}{Theorem}
\newtheorem{col}{Corollary}
\newtheorem{lem}{Lemma}
% ALGORITHMS -----------------------------------------------------

\usepackage[linesnumbered,ruled]{algorithm2e}
\begin{document}


\title{Scalable $K$-Order {LCP} Array Construction for Massive Data}

\author{Yi Wu$^1$, Ge Nong$^{1,3}$, Wai Hong Chan$^2$ and Wei Jun Liu$^1$}

\institute{$^1$Department of Computer Science, Sun Yat-sen University, Guangzhou, China. \\
$^2$SYSU-CMU Shunde International Joint Research Institute, Shunde, China. \\
$^3$Department of Mathematics and Information Technology, Hong Kong Institute of Education, Hong Kong. \\
Email: \{xxx, issng@mail.sysu.edu.cn, waihchan@ied.edu.hk, xxx\}
}

\maketitle

\begin{abstract}
A new method is proposed to compute the  $K$-order longest common prefix (LCP) array for a size-$n$ input string $T$, where the maximum LCP of a pair of suffixes of $T$ are truncated to be at most $K$ characters.
This method can be applied on the internal memory, external memory and  distributed computation models.
For each of these models, the total time and space complexities are $\mathcal{O}(n\log K)$ and $\mathcal{O}(n)$, respectively.
In particular, this method is scalable for a distributed model of $d$ computing nodes, where the time and space complexities are evenly divided onto each node as $O((n\log K)/d)$ and $O(n/d)$, respectively.
\end{abstract}

\section{Introduction}

Suffix array~({SA})~\cite{Manber1993} is a succinct data structure for full-text indexing. In conjunction with the longest common prefix array~({LCPA}), {SA} can emulate a bottom-up or top-down traversal of the corresponding suffix tree~({ST}) and thus becomes popular for a variety of string processing tasks previously tackled by {ST}~\cite{Abouelhodaa2004}.

As far as we know, the most time and space efficient SA and {LCPA} construction algorithms in random access memory~(RAM) model are based on the induced sorting principle~\cite{nong2011,Fischer11}. However, great improvements in data sampling techniques have brought about new challenges as the ever-increasing data sets can no longer be processed internally. To meet the gap, recently, three novel algorithms~\cite{Nong15, Bingmann-Code12, Nong14} have been designed to adapt the internal {SA} construction algorithm {SA-IS}~\cite{nong2011} for sorting suffixes in external memory~(EM). As reported, all the three algorithms achieved a remarkable performance gain in terms of time, space and I/O efficiency against the state-of-the-arts~\cite{Dementiev08}.

As for constructing {LCPA} in external memory,~\cite{Bingmann-Code12} reformulated the {RAM} method formerly presented in~\cite{Fischer11} and made it applicable to running in external disks. Besides,~\cite{Markus2012} proposed a lightweight algorithm for very large collections of sequences, where the Burrow-Wheeler Transform~(BWT) must be calculated simultaneously to facilitate the computation. In addition,~\cite{Felipe2013} adopted the technique of multi-way merge-sort to produce generalized suffix and {LCP} arrays for a data set composed of multiple strings of variable-lengths. Moreover,~\cite{Juha2014} reported an approach that builds the array according to the permuted {LCPA} and inverse {SA} obtained in advance.

It has been observed from~\cite{Felipe2013} that the average longest common prefix~({LCP}) are typically small, especially in genome data sets, such as protein and {DNA}. This enlightened us to design a practical method for computing the $K$-order {LCP} array of input string $T$, where the common prefix length of any two suffixes in $T$ is assumed to be smaller than $K<<|T|$~(e.g. $K=8192$).

The contributions of this work are mainly two aspects:
\begin{enumerate}
\item Our first contribution is to design and implement a $K$-order {LCPA} construction method applicable to typical {RAM} and {EM} models, which can build the {LCPA} in $\mathcal{O}(n\log K)$ time and $\mathcal{O}(n)$ space using the {LCP} batch querying technique~({LCP-BQT})~\cite{Philip2013} previously proposed for sparse SA construction.
\item The existing parallel algorithms for {LCPA} construction are designed for shared-memory models like Bulk Synchronous Parallel~({BSP}) and Parallel Random Access Machine~({PRAM})~\cite{Shun2014,Deo2013}. Our second contribution is to parallelize the proposed method in a distributed system consisting of $d$ computing nodes.
\end{enumerate}

Section~\ref{sec:construction_in_ram}...

\section{K-order LCPA Construction in RAM}\label{sec:construction_in_ram}

\subsection{Notation}\label{subsec:basic_notations}

Consider an input text $T[0,n-1] =T[0]T[1]...T[n-1]$ of size {\em n} drawn from an ordered alphabet $\Sigma$. We assume $T[n-1]$ to be a unique character alphabetically smaller than any characters in $T[0,n-2]$ and introduce the following notations for description clarity.

\begin{itemize}
\item ${\sf pre}(T,i)$ and ${\sf suf}(T,i)$: We write ${\sf pre}(T,i)$ to be the prefix of $T$ running from $T[0]$ to $T[i]$ and write ${\sf suf}(T,i)$ to be the suffix of $T$ running from $T[i]$ to $T[n-1]$.
\item  $SA_T$:  The suffix array of $T$, denoted by $SA_T$, is a permutation of integers $[0,n)$ such that ${\sf suf}(T,SA_T[0])<{\sf suf}(T,SA_T[1])<...<{\sf suf}(T,SA_T[n-1])$ in their lexicographic order.
\item ${\sf lcp}(i,j)$ and $LCPA_T$: We write ${\sf lcp}(i,j)$ to be the {LCP} length of ${\sf suf}(T,i)$ and ${\sf suf}(T,j)$. the {LCP} array of $T$, denoted as $LCPA_T$, consists of $n$ integers taken from $[0,n)$, where $LCPA_T[i]= {\sf lcp}(SA_T[i],SA_T[i-1])$.
\item $\Delta_{k}$: We denote $2^{\log n - k - 1}$ by $\Delta_{k}$.
\end{itemize}

\subsection{LCP Batch Querying Technique}\label{subsec:lcp_batch_querying_technique}

Given $T$ and a set of $b$ pairs of indices $P$, {LCP-BQT} computes ${\sf lcp}(i,j)$ for all pairs $(i,j)\in P$ in $\mathcal{O}(n\log b)$ time using $\mathcal{O}(n)$ {RAM} space. The main idea behind the technique is to find the indices $(i_{fin}, j_{fin})$ for $(i,j)$ such that $T[i,i_{fin}-1]=T[j,j_{fin}-1]$ and $T[i_{fin}] \neq T[j_{fin}]$. To do this, it initially sets $P_0$ to $P$ and performs a loop of $\log b$ rounds, where the goal of round $k\in [0,\log b)$ is to decide whether ${\sf lcp}(i_k,j_k) \le \Delta_k$ or not for each pair $(i_k,j_k)\in P_k$ and generate $P_{k+1}$ as the input for round $k+1$ as following: if $T[i_k,i_k+\Delta_k-1] \neq T[j_k,j_k+\Delta_k-1]$, then insert $(i_k,j_k)$ into $P_{k+1}$; otherwise, insert $(i_k+\Delta_k,j_k+\Delta_k)$ into $P_{k+1}$. The string comparison in concern can be carried out by scanning the two strings rightward and literally comparing the characters in their lexicographic order. However, this operation takes $O(2^{\log n})$ time at worst and thus becomes a performance bottleneck.

As a solution to relieving the time overhead,~\cite{Philip2013} introduced a finger-printing function~\cite{Karp1987} for transforming string comparisons to their integer counterparts that can be finished in constant time. The finger-print~(FP) of $T[i,j]$, namely $FP[i,j]$, is calculated by the formula $FP[i,j] = \sum_{p=i}^{j} \delta^{j-p} \cdot T[p] \, mod \, L$, in which $L$ is a prime and $\delta$ is an integer randomly chosen from $[1,L)$. Obviously, two identical strings always have a common finger-print, while the converse is not true. Fortunately, it has been proved that the error probability of two different strings having a same finger-print can be ignored when $L$ and $\delta$ are very large.

Following the above description, the 3-step algorithmic framework for round $k$ is given below.

\begin{enumerate}[S1.]
\item Scan $T$ rightward to iteratively compute the finger-print of ${\sf pre}(0,l)$ by the formula $FP[0,l] = FP[0,l-1] \cdot \delta + T[l] \,\, mod \,\, L$ and store $FP[0,l]$ in the hash table if $l\in \{ \{i_k-1\}\cup\{j_k-1\}\cup\{i_k +\Delta_{k} - 1\}\cup\{j_k+ \Delta_{k} - 1\},(i_k,j_k)\in P_k\}$.
\item For each $l\in \{\{i_k\}\cup \{j_k\}$, $(i_k,j_k)\in P_k\}$, compute the finger-print of $T[l,l+\Delta_{k} - 1]$ by the formula $FP[l,l+ \Delta_{k} - 1]=FP[0,l+ \Delta_{k} - 1] - FP[0,l-1] \cdot \delta^{\Delta_{k}} \, mod \, L$.
\item For each pair $(i_k,j_k)\in P_k$, compare $FP[i_k,i_k+\Delta_{k} - 1]$ and $FP[j_k,j_k+\Delta_{k} - 1]$. If equal, insert $(i_k+\Delta_{k},j_k+\Delta_{k})$ into $P_{k+1}$; otherwise, insert $(i_k, j_k)$ into $P_{k+1}$.
\end{enumerate}

The following two properties remain invariant during the whole loop.

\begin{itemize}
\item At the beginning of round $k$, $lcp(i_k,j_k) \le 2 \cdot \Delta_{k}$ for each pair $(i_k,j_k) \in P_k$.
\item At the end of round $k$, $lcp(i_{k+1},j_{k+1}) \le \Delta_{k}$ for each pair $(i_{k+1},j_{k+1}) \in P_{k+1}$.
\end{itemize}

After the loop, we have $lcp(i_{\log b},j_{\log b}) \le \frac{n}{b}$ for each pair $(i_{\log b},j_{\log b}) \in P_{\log b}$, and thus can compute $lcp(i_{\log b}, j_{\log b})$ in $\mathcal{O}(\frac{n}{b})$ time by literally compare the characters in ${\sf suf}(T,i_{\log b})$ and ${\sf suf}(T,j_{\log b})$ from left to right. Let $i_{fin} = i_{\log b} + lcp(i_{\log b}, j_{\log b})$ and $j_{fin}= j_{\log b} + lcp(i_{\log b}, j_{\log b})$, then $i_{fin}$ and $j_{fin}$ are the position indices to the right side of $i$ and $j$ such that $T[i,i_{fin}-1] = T[j,j_{fin}-1]$ and $T[i_{fin}] \neq T[j_{fin}]$.

\begin{lem}
\label{thm:lcp:naive}
The {LCP} of any $b$ pairs of suffixes in $T$ can be correctly computed in $\mathcal{O}(n\log b)$ time using $\mathcal{O}(b)$ {RAM} space with a high probability.
\end{lem}
Proof. The time complexity of {LCP-BQT} is dominated by the loop of $\log b$ rounds, where each round takes $\mathcal{O}(n)$ time for step 1 to iteratively compute the finger-prints of ${\sf pre}(T,l)$, and $\mathcal{O}(b)$ time for steps 2-3 to compute and compare the finger-prints of strings. The space in need is limited to $O(b)$ words by employing a hash table for storing and  retrieving the finger-prints.


\subsection{Implementation in RAM}\label{subsec:implementation_in_ram}

We convert the construction problem to the computation of $lcp(i,j)$ for all pairs of indices in $\{(SA_T[1], SA_T[0]),(SA_T[2], SA_T[1])\ldots (SA_T[n], SA_T[n-1])\}$. Parameters and notations listed below are used for presentation clarity, where $i\in [0,n)$ and $k\in [0,\log K)$.

\begin{itemize}
\item $CP_k$ and $PP_k$: arrays of size $2n$. $T[CP_k[2i]+1,CP_k[2i+1]]$ is compared with $T[PP_k[2i]+1,PP_k[2i+1]]$ in round $k$ by their finger-prints to generate $CP_{k+1}$ and $PP_{k+1}$, for $i\in [0,n)$.
\item $ICP_k$ and $IPP_k$: arrays of size $2n$, which are produced by radix-sorting $CP_k$ and $PP_k$, respectively.
\item $HT$: a hash table for storing and retrieving finger-prints of ${\sf pre(T,i)}$, where $i\in \{CP_k[j] \cup PP_k[j], j\in[0,2n)\}$.
\end{itemize}

\begin{algorithm}[hbtp!]
\caption{Compute $K$-Order $LCPA_T$ in RAM}
\label{fig:alg:ram}
{\em lcpa-ram}($T$, $SA_T$, {\em n}, $K$, $HT$){\\
\SetAlgoNoLine
Scan $SA_T$ rightward to produce $CP_0$ and $PP_0$. \\
Let $k = 0$. \\
\While{$k < \log K$}{
\Indentp{-1em}
Radix-sort $CP_k$ and $PP_k$ to produce $ICP_k$ and $IPP_k$. \\
For $i\in [0,n)$, scan $T$ rightward to compute the finger-print of ${\sf pre}(T,i)$ and let $FP[0,i]=HT[i]$ if $i\in \{ICP_k[j] \cup IPP_k[j], j\in[0,2n)\}$. \\
For $i\in [0,n)$, scan $CP_k$ and $PP_k$ rightward to compute and compare $FP[CP_k[2i]+1,CP_k[2i+1]]$ and $FP[PP_k[2i]+1,PP_k[2i+1]]$ for generating $CP_{k+1}$ and $PP_{k+1}$. \\
Let $k = k +1$ and clear $HT$. \\
}
For $i\in [0,n)$, scan $T$, $CP_{\log K}$ and $PP_{\log K}$ rightward to compute $\Upsilon_i = lcp(CP_{\log K}[2i],PP_{\log K}[2i])$. \\
For $i\in [0,n)$, let $lcp(SA_T[i],SA_T[i-1])=CP_{\log K}[2i] +\Upsilon_i-SA_T[i]$. \\
}
\end{algorithm}

Following the ideas in {LCP-BQT}, Algorithm~\ref{fig:alg:ram} computes $CP_0$ and $PP_0$ as following: 1) $CP_0[2i]=SA_T[i]-1$ and $CP_0[2i+1]=SA_T[i]+ \Delta_0 - 1$; and 2) $PP_0[2i]=SA_T[i-1]-1$ and $PP_0[2i+1]=SA_T[i-1]+ \Delta_0 - 1$. When finishing the computation, it proceeds on to performing a loop of $\log K$ rounds in lines 4-9. A key operation in round $k$ is to iteratively compute the finger-prints of ${\sf pre}(T,l)$, where the values are used to calculate $FP[CP_k[2i]+1,CP_k[2i+1]]$ and $FP[PP_k[2i]+1,PP_k[2i+1]]$ for producing $CP_{k+1}$ and $PP_{k+1}$. More specifically, $CP_{k}[2i]$, $CP_{k}[2i+1]$, $PP_{k+1}[2i]$ and $PP_{k+1}[2i+1]$ are increased by $\Delta_{k+1}$ if the two finger-prints are identical; otherwise, $CP_{k+1}[2i+1]$ and $PP_{k+1}[2i+1]$ are increased by $\Delta_{k+1}$. Then the algorithm assigns $ECP_k$ and $EPP_k$ to $ECP_{k+1}$ and $EPP_{k+1}$, respectively. After the while-loop, it takes $\mathcal{O}(n)$ time to compute the {LCP} array in lines 10-11 as $lcp(CP_{\log K}[2i],PP_{\log K}[2i]) \le 1$ holds for any $i \in [0,n)$. This leads us to the following statement.

\begin{lem}
\label{thm:lcp:ram}
Given $T$ and $SA_T$, the $K$-order $LCPA_T$ can be correctly computed in $\mathcal{O}(n\log K)$ time using $\mathcal{O}(n)$ {RAM} space with a high probability.
\end{lem}
Proof. With respect to time complexity, the while-loop spends $\mathcal{O}(n\log K)$ time computing $CP_{\log K}$ and $PP_{\log K}$. On the other respect, it demands $\mathcal{O}(n)$ internal space to maintain $HT$, $CP_k$ and $PP_k$.

\section{$K$-Order LCPA Construction in Disk}\label{sec:construction_in_em}

A hash table is employed in Algorithm~\ref{fig:alg:ram} to store the finger-prints for quick lookups. This is feasible in the RAM model, but not practical when {\em n} becomes larger as the table can not be wholly afforded internally anymore. For the purpose, we reformulate {\em lcpa-ram} to design a disk-friendly external memory (EM) algorithm, called {\em lcpa-em}, where the finger-prints in use are sequentially retrieved from the disk.

\subsection{Preliminaries}

Given the {RAM} capacity $M$ in our {EM} model, $T$ and $SA_T$ are evenly split into $d=n/m$ blocks, where each block is of size $m=O(M)$ and thus can be processed as a whole in {RAM}. We extend $CP_k$ and $PP_k$ previously exploited in {\em lcpa-ram} to define their counterparts $ECP_k$ and $EPP_k$, where both of them consist of $2n$ entries and each entry is a tuple of $\langle idx, pos, fp \rangle$ as described below.
\begin{itemize}
\item $idx$: the index of the entry, where $ECP[i].idx=EPP[i].idx=i$.
\item $pos$: the ending position of ${\sf pre}(0,pos)$.
\item $fp$: the finger-print of ${\sf pre}(0,pos)$.
\end{itemize}

For $i\in [0,n)$, the $fp$ values of $ECP_k[2i]$ and $ECP_k[2i+1]$ are employed to figure out $FP[ECP_k[2i].pos+1, ECP_k[2i+1].pos]$ by the formula $ECP_k[2i+1].fp - ECP_k[2i].fp \cdot \delta^{\Delta_k} \, mod \, L$, where $FP[EPP_k[2i].pos+1, EPP_k[2i+1].pos]$ can be obtained in a similar way.

\subsection{Details}
Different from Algorithm~\ref{fig:alg:ram}, {\em lcpa-em} performs two runs of external memory sort to arrange fixed-size entries by their integer keys of $\log n$ bits during each round. In line 5, entries of $ECP_k$ and $EPP_k$ are sorted by $pos$ to form $IECP_k$ and $IEPP_k$ for iteratively computing the required finger-prints, and sorted back by $idx$ to compute $ECP_{k+1}$ and $EPP_{k+1}$ in lines 7-8. Given $M=\Omega(nW)^{0.5}$, where $W$ is the size of {I/O} buffers large enough to amortize the overhead of accesses to disks, each run can be done in $\mathcal{O}(n)$ time and space by adopting a multi-way external memory radix-sort of two passes, of which the first pass sorts the lowest $0.5\log n$ bits and the second pass sorts the highest $0.5\log n$ bits. Thus we come to the following conclusion.

\begin{lem}
\label{thm:lcp:em}
Given $T$ and $SA_T$, the $K$-order $LCPA_T$ can be correctly computed in $O(n \log K)$ time using $O(n)$ {EM} space with a high probability.
\end{lem}

\begin{algorithm}[hbtp!]
\caption{Compute $K$-Order $LCPA_T$ in EM}
\label{fig:alg:em}
{\em lcpa-em}($T$, $SA_T$, {\em n}, $K$){\\
\SetAlgoNoLine
Scan $SA_T$ rightward to produce $ECP_0$ and $EPP_0$.\\
Let $k = 0$. \\
\While{$k < \log K$}{
\Indentp{-1em}
Radix-sort $ECP_k$ and $EPP_k$ by $pos$ to form $IECP_k$ and $IEPP_k$. \\
For $i\in [0,n)$ and $j\in [0,2n)$, scan $T$ rightward to iteratively compute the finger-print of ${\sf pre}(T,i)$ and set $IECP_k[j].fp$ or $IEPP_k[j].fp$ to $FP[0,i]$ if $IECP_k[j].pos = i$ or $IEPP_k[j].pos = i$. \\
Radix-sort $IECP_k$ and $IEPP_k$ to $ECP_k$ and $EPP_k$ by $idx$. \\
For $i \in [0,n)$, scan $ECP_k$ and $EPP_k$ rightward to compute and compare each pair of $(FP[ECP_k[2i].pos+1,ECP_k[2i+1].pos], FP[EPP_k[2i].pos+1,EPP_k[2i+1].pos])$ for generating $ECP_{k+1}$ and $EPP_{k+1}$. \\
Let $k = k + 1$. \\
}
For $i \in [0,n)$, scan $T$, $ECP_{\log K}$ and $EPP_{\log K}$ rightward to compute $\Upsilon_i = lcp(ECP_{\log K}[2i].pos,EPP_{\log K}[2i].pos)$. \\
For $i \in [0,n)$, let $lcp(SA_T[i],SA_T[i-1])=ECP_{\log K}[2i].pos+\Upsilon_i-SA_T[i]$.\\
}
\end{algorithm}

\subsection{Optimization}\label{subsec:optimization}

The while-loop is time-consuming in {lcpa-em}, therefore we adapt the algorithm to generate $ECP_{k+2}/EPP_{k+2}$ directly from $ECP_k/EPP_k$ for reducing loop rounds by half. The procedure in lines 8-9 is revised as below.

\begin{enumerate}[S1.]
\item Compute and compare the finger prints of $T[ECP_k[2i].pos+1,ECP_k[2i+1].pos]$ and $T[EPP_k[2i].pos+1,EPP_k[2i+1].pos]$. If equal, performs S2; otherwise, goes to S3.
\item Compute and compare the finger-prints of $T[ECP_k[2i+1].pos+1,ECP_k[2i+1].pos+\Delta_{k+2}]$ and $T[EPP_k[2i+1].pos+1,EPP_k[2i+1].pos+\Delta_{k+2}]$. If equal, increases $ECP_k[2i].pos$, $ECP_k[2i+1].pos$, $EPP_k[2i].pos$ and $EPP_k[2i+1].pos$ by $\Delta_{k+1}+\Delta_{k+2}$; otherwise, increases them by $\Delta_{k+1}$.
\item Compute and compare the finger-prints of $T[ECP_k[2i].pos+1,ECP_k[2i].pos+\Delta_{k+2}]$ and $T[EPP_k[2i].pos+1,EPP_k[2i].pos+\Delta_{k+2}]$. If equal, increases $ECP_k[2i].pos$, $ECP_k[2i+1].pos$, $EPP_k[2i].pos$ and $EPP_k[2i+1].pos$ by $\Delta_{k+2}$.
\item Let $ECP_{k+2}=ECP_{k}$ and $EPP_{k+2}=EPP_{k}$.
\item Let $k = k+2$.
\end{enumerate}

Notice that the required finger-prints in S1-S3 can be obtained following the way described in {lcpa-em}. As shown in Section~\ref{sec:experimental_results}, the revised algorithm, namely {lcpa-em-m}, achieves a substantial improvement against the prototype.

\subsection{Discussion}\label{subsec:discussions}

In this part, we demonstrate how to parallelize Algorithm~\ref{fig:alg:em} in a distributed system consisting of $d$ computing nodes $\{N_0, N_1, ...N_{d-1}\}$. All nodes are interconnected with each other by a gigabit switch operating in full duplex mode where the internal and external memory capacities of each node are $M$ and $E$, respectively.

For $i\in [0,d)$ and $j\in [0,e)$, we evenly partition $T$ and $SA_T$ into $d=n/e$ blocks of size $e=\mathcal{O}(E)$ and allocate them among the computing nodes in a manner of one block per node as below.

\begin{itemize}
\item $T_i$: the $i$-th block of $T$ residing on node $N_i$, where $T_i[j] = T[ie+j]$.
\item $SA_{T_i}$: the $i$-th block of $SA_T$ residing on node $N_i$, where $SA_{T_i}[j] = SA_T[ie+j]$.
\end{itemize}

Recall that {\em lcpa-em} computes $ECP_{\log K}$ and $EPP_{\log K}$ via two runs of radix-sort in external memory. This is emulated in Algorithm~\ref{fig:alg:ds} by using a set of sending/receving buffers for data exchange among the computing nodes. After the while-loop, the {LCP} array of $T[ie,ie+e)$ can be figured out in linear time according to $ECP_{i,{\log K}}$, $EPP_{i,{\log K}}$ and $SA_{T_i}$ residing on $N_i$. Finally, we can simply concatenate the local result on each node to form the global one.

\begin{algorithm}[hbtp!]
\caption{Compute $K$-Order $LCPA_T[ie,ie+e)$ on $N_i$}
\label{fig:alg:ds}
{\em lcpa-ds}($T_i$, $SA_{T_i}$, $e$, $K$){\\
\SetAlgoNoLine
Scan $T_i$ rightward to compute $ECP_{i,0}$ and $EPP_{i,0}$. \\
Let $k=0$. \\
For $j\in[0,d)$, create sending buffers $SB1_{i,j}$ and $SB2_{i,j}$. \\
Create receiving buffers $RB1_i$ and $RB2_i$. \\
\While{$k < \log K$}{
\Indentp{-1em}
Scan $SA_{T_i}$ rightward to compute $ECP_{i,k}$ and $EPP_{i,k}$. \\
For $j\in[0,d)$ and $p\in[0,2e)$, scan $ECP_{i,k}$ and $EPP_{i,k}$ rightward to cache $ECP_{i,k}[p]$ in $SB1_{i,j}$ or $EPP_{i,k}[p]$ in $SB2_{i,j}$ if $ECP_{i,k}[p].pos$ or $EPP_{i,k}[p].pos$ belong to $[je,je+e)$. \\
For $j\in[0,d)$, send entries in $SB1_{i,j}$ and $SB2_{i,j}$ to $N_j$. \\
For $j\in[0,d)$, cache entries from $SB1_{i,j}$ and $SB2_{i,j}$ in $RB1_i$ and $RB2_i$. \\
Radix-sort entries in $RB1_i$ and $RB2_i$ by $pos$ to produce $IECP_{i,k}$ and $IEPP_{i,k}$. \\
For $p\in[0,e)$ and $q\in [0,2e)$, scan $T_i$ rightward to iteratively compute the finger-print of ${\sf pre}(T,ie+p)$ and assign $FP[0,ie+p]$ to $IECP_{i,k}[q].fp$ or $IEPP_{i,k}[q].fp$ if $IECP_{i,k}[q].pos = ie+p$ or $IEPP_{i,k}[q].pos = ie+p$. \\
For $j\in[0,d)$ and $p\in[0,2e)$, scan $IECP_i$ and $IEPP_i$ rightward to cache $IECP_{i,k}[p]$ in $SB1_{i,j}$ or $IEPP_{i,k}[p]$ in $SB2_{i,j}$ if $IECP_{i,k}[p].pos$ or $IEPP_{i,k}[p].pos$ belong to $[je,je+e)$. \\
For $j\in[0,d)$, send entries in $SB1_{i,j}$ and $SB2_{i,j}$ to $N_j$. \\
For $j\in[0,d)$, cache entries from $SB1_{i,j}$ and $SB2_{i,j}$ in $RB1_i$ and $RB2_i$. \\
Radix-sort entries in $RB1_i$ and $RB2_i$ by $idx$ to $ECP_{i,k}$ and $EPP_{i,k}$. \\
For $p\in [0,e)$, scan $ECP_{i,k}$ and $EPP_{i,k}$ rightward to compute and compare the finger-prints of $T[ECP_{i,k}[2p].pos+1, ECP_{i,k}[2p+1].pos]$ and $T[EPP_{i,k}[2p].pos+1, EPP_{i,k}[2p+1].pos]$ for generating $ECP_{i,k+1}$ and $EPP_{i,k+1}$. \\
Let $k=k+1$. \\
}
For $p\in [0,e)$, scan $T_i$, $ECP_{i,\log K}$ and $EPP_{i,\log K}$ rightward to literally compute $\Upsilon_{i,p}=lcp(ECP_{i,\log K}[2p].pos,EPP_{i,\log K}[2p].pos)$. \\
For $p\in [0,e)$, let $lcp(SA_{T_i}[p],SA_{T,i}[p-1])=ECP_{i,\log K}.pos + \Upsilon_{i,p} - SA_{T_i}[p]$. \\
}
\end{algorithm}

\begin{lem}
\label{thm:lcp:pdm}
Given $T$ and $SA_T$, the $K$-order $LCPA_T$ can be correctly computed in $\mathcal{O}(\frac{n}{d}\log K)$ time using $\mathcal{O}(\frac{n}{d})$ EM space on each computing node with a high probability.
\end{lem}
Proof. Algorithm~\ref{fig:alg:ds} performs radix-sorts among the computing nodes, where the time and space overhead for data transmission sums up to $\mathcal{O}(e\log K)$ during the whole loop. This is because each node sends and receives $\mathcal{O}(e)$ entries per round.



\section{Experimental Results}\label{sec:experimental_results}

The performance of {\em lcpa-em} and {\em lcpa-em-m} are evaluated on a real data set collected from the web site \url{http://download.wikimedia.org/enwiki/}. We conduct the experiments on a platform equipped with Intel Cuo i5 4200M CPU, 4GiB RAM and a 500GiB hard disk.

Instead of to develop a radix sorter specific for our purpose, we use  {STXXL}\cite{Dementiev2007} to perform the external memory sorts in our programs. {STXXL} is a {C++} {STL} library designed for efficient computation in external memory, and freely available at \url{xxx}. Benefit from the powerful priority queues provided by {STXXL}, the codes for {lcpa-em} and {lcpa-em-m} are only 400 and 600 lines, respectively.

In Table~\ref{tbl:exp:result}, each time result is a mean of two runs of the programs monitored by the shell command ``time". As can be seen, the running time of {lcpa-em-m} is significantly faster than that of {lcpa-em} in all cases, where the loop rounds of them are 7 and 13, respectively. We also observed that the processing time of each character per round varies from $1.99\mu s$ to $4.18\mu s$ as the size of corpora increases from $200M$ to $2G$. This sub-linear phenomenon is partly due to the non-linear {EM} sorts conducted by {STXXL}.

\begin{table}
\centering
\label{tbl:exp:result}
\caption{\label{tbl:exp:result} Number of rounds of the while-loop and mean running time in $\mu s/ch$ per round, $K=8192$.}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
Size &
\multicolumn{2}{c|}{lcpa-em} &
\multicolumn{2}{c|}{lcpa-em-m} \\
\cline{2-5}
 (MiB) & Round & Time & Round & Time\\
\hline
200 & 13 & 3.18 & 7 & 1.99\\
\hline
400 & 13 & 3.17 & 7 & 2.01\\
\hline
600 & 13 & 3.32 & 7 & 2.27\\
\hline
800 & 13 & 3.45 & 7 & 2.65\\
\hline
1024 & 13 & 5.76 & 7 & 3.30\\
\hline
2048 & 13 & 5.88 & 7 & 4.18\\
\hline
\end{tabular}
\end{table}

\section{Conclusion}\label{sec:conclusion}

We present in this paper a practical $K$-order LCPA construction method that can be easily applied on both the internal memory and the external memory models. The program for {\em lcpa-em-m} is less than 600 lines when using {STXXL} to implement the external sorts. We also show that the proposed method is straightforward to be extended for running on a typical distributed system of a cluster of $d$ computing nodes, where the time and space complexities are evenly divided onto each node as $O(\frac{n}{d}\log K)$ and $O(\frac{n}{d})$, respectively. The proposed algorithms are simple in design and universal for the RAM, disk and distributed models. Its implementations on all these models are not difficult and easily to be deployed.
A cluster of computers in a local area network are commonly available in practice, but there is currently lack of scalable LCPA construction algorithms for such a distributed model, in this sense, 
our algorithms provide a candidate solution to meet this demand.

\bibliographystyle{unsrt}
\bibliography{bibfile}

\end{document}
